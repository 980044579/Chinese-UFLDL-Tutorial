# 使用卷积进行特征提取（Feature Extraction Using Convolution）  
##  
## 概览（Overview）  

在之前的练习中，练习问题涉及到的图片其分辨率都偏低，例如小图像修补程序和小图像的手写数字识别。而在本节中，我们将会开发一种方法，它能够扩展先前学到的方法在更实际的大图像数据集上。  

## 全连接网络（Fully Connected Networks）  

在稀疏编码器中，一种设计选择是我们先前已经实现的“全连接”，即所有的隐含层单元与所有输入单元完全连接起来。在我们先前的练习中，使用的是相对较小的图像（例如，在稀疏编码的任务中8x8像素大小的图像，MNIST数据集中28x28像素大小的图像），这种“全连接”方式的特种学习在对整个图像上计算是可行的。然而，对于更大图像（例如，96x96像素大小的图像）的学习来说，可能会因为特征学习会在整个图像上进行（全连接网络），其计算代价是很大的——您要有104个输入单元，假设您想学习 100 个特征，您就会对 106 个参数按照顺序进行学习。相较于28x28像素大小的图像，在前向和反向传播的计算上也会慢大约102倍。  

## 局部连接网络（Locally Connected Networks）  

这个问题的一种简单解决方案是限制隐含单元与输入单元的连接数目，也就是说，只允许隐含单元连接输入单元中的一个小的子集。具体而言，每个隐藏单元将连接到输入像素中的一个小的连续区域。（对于不同于图像的输入形式，也有一种自然的方式来选择从输入单元到一个隐含单元的“连续组”，例如，对于音频，一个隐藏单元可能被连接到一个与之特定时间跨度对应的音频剪辑的输入单元上。）  

局部连接网络的这一想法也借鉴了在生物学上早期视觉系统的观点。具体而言，视觉皮层的神经元有着局部感受区域（即，它们只会对某一位置的刺激做出反应）。  

## 卷积（Convolutions）  

自然世界中的图像有着“固定不变”的属性，这也意味这图像的某一部分的数据和另一部分的数据是一样的。这表明，我们在一张图片上某部分的特征也可应用到该图片的其它部分，并且我们可以基于这一观点——使用不同的特征，应用到局部数据一样但不同的位置上。  

更确切地说，从大的图像上随机地抽样小图片（比方说8x8大小的图片）做特征学习，我们可以将这个8x8大小的特征检测器应用到这幅图片的任何地方。具体而言，我们可以把学到的8x8特征，通过将它们与更大图片“卷”起来的方式，在同一张图片上获得在每个位置处不同的特征激活值。  

讲个具体的例子，假设您已经从96x96大小的图片上做了8x8大小的抽样的特征学习。再进一步假设，这一过程是通过有着100个隐含单元的自动编码器完成的。为了获得卷积特征（即96x96大小的图片上每8x8大小范围的特征，这个8x8区域是从$(1,1), (2,2), ...(89,89)$ ），您将会提取8x8大小的图片，通过您训练的稀疏自动编码器来获取特征激活。这将会产生100组的89x89大小的卷积特征。